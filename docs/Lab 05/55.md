# Hyperparameter Tuning

Another fancy classifier is called a random forest ([Breiman 2001](https://link.springer.com/article/10.1023/A:1010933404324)). A random forest is a collection of random trees in that the predictions of which are used to compute an average (regression) or vote on a label (classification). Because random forests are so good, we need to make things a little harder for it to be interesting. Do that by adding noise to the training data:

```javascript
var sample = landsat.select(predictionBands)
.sampleRegions({
  collection: trainingFeatures.map(function(f) {
    return  f.buffer(300)}), properties: ['class'], scale: 30});  

var classifier =  ee.Classifier.smileRandomForest(10)
				.train({features: sample,
                classProperty: 'class',
                inputProperties: predictionBands
               });
var classified =  landsat.select(predictionBands).classify(classifier);   Map.addLayer(classified, {min: 0, max: 2,  palette: ['red', 'green', 'blue']}, 'classified')                                                                     
```

Note that the only parameter to the classifier is the number of trees (10). How many trees should you use? Making that choice is best done by hyperparameter tuning. For example,  

```javascript
sample  = sample.randomColumn();
var train = sample.filter(ee.Filter.lt('random', 0.6));
var test = sample.filter(ee.Filter.gte('random', 0.6));
var numTrees = ee.List.sequence(5, 50, 5);
var accuracies = numTrees.map(function(t) {
  var classifier =  ee.Classifier.smileRandomForest(t).train({
    features: train,
    classProperty: 'class',
    inputProperties: predictionBands
  });
  return test.classify(classifier)
    .errorMatrix('class',  'classification')
    .accuracy();
});
print(ui.Chart.array.values({
  array: ee.Array(accuracies),
  axis: 0,
  xLabels: numTrees
}));  
```

You should see something like the following chart, in which number of trees is on the x-axis and estimated accuracy is on the y-axis:

![Chart, scatter chart  Description automatically generated](./clip_image001.png)

 

First, note that we always get very good accuracy in this toy example. Second, note that 10 is not the optimal number of trees, but after adding more (up to about 20 or 30), we don't get much more accuracy for the increased computational burden. So 20 trees is probably a good number to use in the context of this silly example.

