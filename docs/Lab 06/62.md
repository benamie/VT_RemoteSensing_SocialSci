# Regression

In the present context, regression means predicting a numeric variable instead of a class label. No lab on regression would be complete without the requisite introduction to least squares regression.

## Ordinary Least Squares (OLS)

A very [ordinary regression](https://en.wikipedia.org/wiki/Ordinary_least_squares) is when *G* is a linear function of the form *G*(**p**) = **βp** where **β** is a vector of coefficients. Once *G* is trained by some training set **T**, guess the value for some unknown **p** by multiplying it with **β**. Suppose the goal is to estimate percent tree cover in each Landsat pixel.


i.Import data to use as known values for *g*. Search 'vegetation continuous fields' and import 'MOD44B.051'. Get the most recent image out of this collection:

```javascript
var tree = ee.Image(mod44b.sort('system:time_start', false).first());
```

Since water is coded as 200 in this image, replace the 200's with 0's and display the result:

```javascript
var percentTree = tree.select('Percent_Tree_Cover')
  [.where](https://developers.google.com/earth-engine/apidocs/ee-image-where?hl=en)(tree.select('Percent_Tree_Cover').eq(200), 0);
Map.addLayer(percentTree, {max: 100}, 'percent tree cover'); 
```

Note that this image represents percent tree cover at 250 meter resolution in 2010.


Import data to use as predictor variables (**p**). Search 'landsat 5 raw' and import 'USGS Landsat 5 TM Collection 1 Tier 1 Raw Scenes'. Name the import l5raw. Filter by time and the [WRS-2](https://www.usgs.gov/faqs/what-worldwide-reference-system-wrs?qt-news_science_products=0#qt-news_science_products) path and row to get only scenes over the San Francisco bay area in 2010

```javascript
var l5filtered = l5raw.filterDate('2010-01-01', '2010-12-31')
    .filterMetadata('WRS_PATH', 'equals', 44)
    .filterMetadata('WRS_ROW', 'equals', 34);
```

Use an Earth Engine algorithm to get a cloud-free composite of Landsat imagery in 2010:

```javascript
var landsat = ee.Algorithms.Landsat.simpleComposite({
 collection: l5filtered,
 asFloat: true
});
Map.addLayer(landsat, {bands: ['B4', 'B3', 'B2'], max: 0.3}, 'composite');
```

Specify the bands of the Landsat composite to be used as predictors (i.e. the elements of **p**):

```javascript
var predictionBands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7'];
```


Now that all the input data is ready, build **T**. It's customary to include a constant term in linear regression to make it the [best linear unbiased estimator](https://en.wikipedia.org/wiki/Gauss–Markov_theorem). Stack a constant, the predictor variables and the image representing known *g*:

```javascript
var trainingImage = ee.Image(1)
  .addBands(landsat.select(predictionBands))
  .addBands(percentTree);
```

Sample this stack at 1000 locations to get **T** as a table:

```javascript
var training = trainingImage.sample({
 region: l5filtered.first().geometry(), 
 scale: 30, 
 numPixels: 1000
});
```

Inspect the first element of **T** to make sure it's got all the data you expect. 

The next step is to train *G*. Make a list of the variable names, predictors followed by *g*:

```javascript
var trainingList = ee.List(predictionBands)
  .insert(0, 'constant')
  .add('Percent_Tree_Cover');
```


In Earth Engine, [linear regression is implemented as a Reducer](https://developers.google.com/earth-engine/reducers_regression). This means that training *G* is a reduction of the **T** table, performed using the list of variables as an input. The argument (8) tells the reducer how many of the input variables are predictors:

```javascript
var regression = training.reduceColumns({
 reducer: [ee.Reducer.linearRegression](https://developers.google.com/earth-						   engine/apidocs/ee-reducer-linearregression)(8), 
 selectors: trainingList
});
```


Observe that the output is an object with a list of coefficients (in the order specified by the inputs list) and the root mean square [residual](https://en.wikipedia.org/wiki/Errors_and_residuals). To use the coefficients to make a prediction in every pixel, first turn the output coefficients into an image, then perform the multiplication and addition that implements **βp**: 

```javascript
var coefficients = ee.Array(regression.get('coefficients'))
  .project([0])
  .toList();
var predictedTreeCover = ee.Image(1).addBands(landsat.select(predictionBands))
				.multiply(ee.Image.constant(coefficients))
				.reduce(ee.Reducer.sum())
				.rename('predictedTreeCover');
Map.addLayer(predictedTreeCover, {min: 0, max: 100}, 'prediction');
```

Carefully inspect this result. Is it satisfactory? If not, it might be worth testing some other regression functions, adding more predictor variables, collecting more training data, or all of the above.

